---
title: "A/B Experiment: iRex 07 February Repeat"
subtitle: "Summary & Stats Analysis"
date: "26/02/2021"
output: html_document
toc: true
toc_float: true
ceruleancss: picture.css
---
<br>
<br>

# {.tabset .tabset-fade}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
invisible(gc())
library(tidyverse)
library(dbplyr)
library(knitr)
library(gridExtra)
library(grid)
library(ggplot2)
library(reshape2)
library(kableExtra)
library(rJava)
library(xlsx) #you may have issue with this package and rJava when installing go here https://stackoverflow.com/questions/62012760/r-xlsx-package-can-not-be-used and read the "How do i tell whether the JRE is isntalled" and follow solution 2.
```


```{r dataload, include=FALSE}
# Run the calculator - you should have edited this script in advance to contain the data you need.
#source(paste0(getwd(),"/Significance Calculator VB.R"))
```

```{r read_in_data, echo=FALSE}

stats_results_edit_new_trend<- read.csv(paste0(getwd(),"/stats_results_editorial-new-trending.csv")) %>%filter(metric != 'clicks')
stats_results_binge_worthy<- read.csv(paste0(getwd(),"/stats_results_binge-worthy.csv"))%>%filter(metric != 'clicks')
stats_results_homepage<- read.csv(paste0(getwd(),"/stats_results_whole-homepage.csv"))%>%filter(metric != 'clicks')
stats_results_product<- read.csv(paste0(getwd(),"/stats_results_whole-product.csv"))%>%filter(metric != 'clicks')


var_totals_edit_new_trend<-read.csv(paste0(getwd(),"/var_totals_editorial-new-trending.csv"))
var_totals_binge_worthy<-read.csv(paste0(getwd(),"/var_totals_binge-worthy.csv"))
var_totals_homepage<-read.csv(paste0(getwd(),"/var_totals_whole-homepage.csv"))
var_totals_product<-read.csv(paste0(getwd(),"/var_totals_whole-product.csv"))

freq<- read.csv("vb_frequency_homepage_metrics.csv")


hids_visits_summary<- read.csv(paste0(getwd(),"/hids_visits_summary.csv"))

#Add an "all ages" set to hids and visits data
hids_visits_summary<- 
  hids_visits_summary %>% 
  bind_rows(
    hids_visits_summary %>%
      group_by(exp_group) %>%
      summarise(hids = sum(hids),visits = sum(visits)) %>%
      mutate(age_range = 'all 16+')
    ) %>%
  mutate(hids2 = signif(hids, 3),
         visits2 = signif(visits, 3)) %>%
  select(-hids,-visits) %>%
  rename(hids = hids2, visits = visits2)
```

```{r write all df to excel, echo=FALSE, results = "asis"}
##Information to complete
start_date = "2021-02-11"
end_date = "2021-02-24"
exp_title = "iRex_07_February_Repeat"
fileName<- paste0(exp_title,"-",start_date,"_",end_date,".xlsx")

#get the name of all the df in the document
my_df_names <-ls()[sapply(ls(), function(x) class(get(x))) == 'data.frame']

#load the actual data frames into a list
dfList <- list()
for (i in 1:length(my_df_names)) {
  dfList[[i]] <- get(my_df_names[i])
}
names(dfList) <- my_df_names

#Create file
for(name in 1:length(dfList)){
  write.xlsx(x = as.data.frame(dfList[[name]]),
             file = fileName,
             sheetName = my_df_names[[name]],
             row.names = FALSE,
             col.name = TRUE,
             append = TRUE)
}

```

```{r define_functions, echo=FALSE}
get_uplift_table<-function(df, age_group, metric_name, comp_var){
  uplift_table<- df %>%
    filter(age_range == age_group &
             comparison %in% comp_var &
             metric == metric_name) %>% 
    mutate( uplift2 = ifelse(significance == 'Significant', uplift, 'NA'), #alter table for if value is not significant
            performance2 = ifelse(significance == 'Significant', performance, 'not significant')) %>%
    select(-uplift, -performance) %>%
    rename(uplift = uplift2, performance = performance2)%>%
    select(variable, comparison, metric, performance, uplift) %>%
    select(-metric)
  return(uplift_table)
}

#function to sumarise the total starts/clicks/completes and join to the number of hids and visits
get_summary_values<-function(metric_df, hids_visits_df ){
summary_values<-
  metric_df %>%
  mutate(
    clicks2 = signif(clicks, 3),
    starts2 = signif(starts, 3),
    completes2 = signif(completes, 3)
  ) %>%
  select(-clicks,-starts,-completes) %>%
  rename(clicks = clicks2,
         starts = starts2,
         completes = completes2) %>%
  left_join(hids_visits_df
,
    by = c("age_range" = "age_range",
           "variant" = 'exp_group')
  ) %>%
  select(age_range, variant, hids, visits,clicks, starts, completes)
return(summary_values)
}
```
## Experiment Summary & Headlines

### Overview
<br>

#### Hypothesis

<b>IF</b> we sort a list of programmes on the Featured and Binge Worthy series rows using the iRex sorting algorithm

<b>THEN</b> we will increase the consumption of content from these rows

<b>DUE TO</b> the iRex sorting algorithm serving more relevant content on these rows than the current sorting algorithm provided by Think Analytics

<br>

#### Variants
There were three variants and the control in this experiment. Each variant was given a different iRex algorithm and the control used a recomendation algorithm provided by Think Analytics.
The variants and engines were:

* Control saw *think-personal-iplayer-homepg-featuredsort* 
* Variation1 saw *irex-v1.2-total-score-wnext-sorting-k-50*
* Varaition2 saw *irex-profile-v1-sorting*
* Variation3 saw *irex-profile-v1-wnext-sorting*

#### Duration & Audience
The experiment ran for **2 weeks** between **2021-02-11** and **2021-02-24** to **100%** of the audience on homepage. There were 4 variants (control, v1, v2, & v3) with approximately **2.3 million signed in users** in each experiment group. 

<br>

#### Test Duration & Sample Size
In the experiment design phase, we calculated the test should run for two weeks to be able to see a 2% minimum detectable change.  
<br>
The experiment met this criteria.  
<br>

### Headline Results

<br>

##### Editorial New & Trending
```{r significance_summary_edit_new_trend, echo=FALSE}
#See how many variant combinations are significant
signif_starts<-stats_results_edit_new_trend %>%
  filter(metric =='starts') %>% 
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>% 
  filter(significance == "Significant")
if(nrow(signif_starts) ==0) {
  signif_starts<- data.frame(significance = "Significant", n =0, percent = 0)
}

#See how many variant combinations are significant
signif_completes<-stats_results_edit_new_trend %>%
  filter(metric =='completes') %>%
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>%
  filter(significance == "Significant")
if(nrow(signif_completes) ==0) {
  signif_completes<- data.frame(significance = "Significant", n =0, percent = 0)
}
```

For this homepage module `r if(signif_starts$percent ==100 ) {"all of the"} else if(signif_starts$percent <100 & signif_starts$percent >=60) {"most of the"} else if(signif_starts$percent <160 & signif_starts$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric comparisons showed significant results for the metric "starts" and `r if(signif_completes$percent ==100 ) {"all of the"} else if(signif_completes$percent <100 & signif_completes$percent >=60) {"most of the"} else if(signif_completes$percent <160 & signif_completes$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric "completes" comparisons. There were between 1.2 and 1.4 millions clicks on the editorial new & trending rail for each variant, between 710,000 and 810,000 play starts (30s metric) and between 480,000 and 560,000 play completes (90% content competion). A detailed breakdown can be found on the module specific tab.

<br>
Across all users, **variant three performed the best** with an uplift for play completes of 8.8% whilst **variant two performed the worst** at 5.9% below the control.

```{r headline_table_edit_new_trend, echo=FALSE}

age_range<-'all 16+'
rail_name<-'Editorial New Trending'
comparison_var<- c('control') #c('control', 'var1', 'var2', 'var3')

df<-left_join(
  get_uplift_table(stats_results_edit_new_trend, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_edit_new_trend, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

```

<br>

##### Binge-Worthy
```{r significance_summary_binge_worthy, echo=FALSE}
#See how many variant combinations are significant
signif_starts<-stats_results_binge_worthy %>%
  filter(metric =='starts') %>% 
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>% 
  filter(significance == "Significant")
if(nrow(signif_starts) ==0) {
  signif_starts<- data.frame(significance = "Significant", n =0, percent = 0)
}

#See how many variant combinations are significant
signif_completes<-stats_results_binge_worthy %>%
  filter(metric =='completes') %>%
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>%
  filter(significance == "Significant")
if(nrow(signif_completes) ==0) {
  signif_completes<- data.frame(significance = "Significant", n =0, percent = 0)
}
```

For the this homepage module `r if(signif_starts$percent ==100 ) {"all of the"} else if(signif_starts$percent <100 & signif_starts$percent >=60) {"most of the"} else if(signif_starts$percent <160 & signif_starts$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric comparisons showed significant results for the metric "starts" and `r if(signif_completes$percent ==100 ) {"all of the"} else if(signif_completes$percent <100 & signif_completes$percent >=60) {"most of the"} else if(signif_completes$percent <160 & signif_completes$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric "completes" comparisons.  There were between 1.1 and 1.5 millions clicks on the binge-wothy rail for each variant, between 700,000 and 960,000 play starts (30s metric) and between 470,000 and 680,000 play completes (90% content competion). A detailed breakdown can be found on the module specific tab.

<br>

Across all users, **variant three performed the best** with an uplift for play completes of 13.1% whilst **variant two performed the worst** at 21.4% below the control.

```{r headline_table_binge_worthy, echo=FALSE}

age_range<-'all 16+'
rail_name<-'Binge Worthy'
comparison_var<- c('control') #c('control', 'var1', 'var2', 'var3')

df<-left_join(
  get_uplift_table(stats_results_binge_worthy, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_binge_worthy, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

```
<br>

##### Whole Homepage
```{r significance_summary_whole_homepage, echo=FALSE}
#See how many variant combinations are significant
signif_starts<-stats_results_homepage %>%
  filter(metric =='starts') %>% 
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>% 
  filter(significance == "Significant")
if(nrow(signif_starts) ==0) {
  signif_starts<- data.frame(significance = "Significant", n =0, percent = 0)
}

#See how many variant combinations are significant
signif_completes<-stats_results_homepage %>%
  filter(metric =='completes') %>%
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>%
  filter(significance == "Significant")
if(nrow(signif_completes) ==0) {
  signif_completes<- data.frame(significance = "Significant", n =0, percent = 0)
}
```

For the whole homepage `r if(signif_starts$percent ==100 ) {"all of the"} else if(signif_starts$percent <100 & signif_starts$percent >=60) {"most of the"} else if(signif_starts$percent <160 & signif_starts$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric comparisons showed significant results for the metric "starts" and `r if(signif_completes$percent ==100 ) {"all of the"} else if(signif_completes$percent <100 & signif_completes$percent >=60) {"most of the"} else if(signif_completes$percent <160 & signif_completes$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric "completes" comparisons. There were aproximately 11 millions clicks on the homepage for each variant, between 8.5 million play starts (30s metric) and 6 million play completes (90% content competion). A detailed breakdown can be found on the homepage specific tab.

<br>
Across all users, **no variant had a significant impact on the homepage consumption**.

```{r headline_table_whole_homepage, echo=FALSE}

age_range<-'all 16+'
rail_name<-'Homepage'
comparison_var<- c('control') #c('control', 'var1', 'var2', 'var3')

df<-left_join(
  get_uplift_table(stats_results_homepage, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_homepage, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
 
##Commenting this out as the results are not significant                                                   
# df%>% 
# kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
#       caption = paste0(rail_name,": ",age_range),
#     escape = F) %>%
#   add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
#   kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
#   footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")


```

<br>

##### Whole Product
```{r significance_summary_whole_product, echo=FALSE}
#See how many variant combinations are significant
signif_starts<-stats_results_product %>%
  filter(metric =='starts') %>% 
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>% 
  filter(significance == "Significant")
if(nrow(signif_starts) ==0) {
  signif_starts<- data.frame(significance = "Significant", n =0, percent = 0)
}

#See how many variant combinations are significant
signif_completes<-stats_results_product %>%
  filter(metric =='completes') %>%
  group_by(significance) %>%
  count() %>%
  ungroup() %>%
  mutate(percent= round(prop.table(n) * 100,0)) %>%
  filter(significance == "Significant")

if(nrow(signif_completes) ==0) {
  signif_completes<- data.frame(significance = "Significant", n =0, percent = 0)
}
```

For the whole product `r if(signif_starts$percent ==100 ) {"all of the"} else if(signif_starts$percent <100 & signif_starts$percent >=60) {"most of the"} else if(signif_starts$percent <160 & signif_starts$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric comparisons showed significant results for the metric "starts" and `r if(signif_completes$percent ==100 ) {"all of the"} else if(signif_completes$percent <100 & signif_completes$percent >=60) {"most of the"} else if(signif_completes$percent <160 & signif_completes$percent >=100) {"a few of the"} else {"less than 10% of" } `  metric "completes" comparisons. There were aproximately 44 millions clicks on the product for each variant, 33 million play starts (30s metric) and 23 million play completes (90% content competion). A detailed breakdown can be found on the product specific tab.

<br>
Across all users, **no variant had a significant impact on the product consumption**.

```{r headline_table_whole_product, echo=FALSE}

age_range<-'all 16+'
rail_name<-'product'
comparison_var<- c('control') #c('control', 'var1', 'var2', 'var3')

df<-left_join(
  get_uplift_table(stats_results_product, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_product, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
 
##Commenting this out as the results are not significant                                                   
# df%>%
# kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"),
#       caption = paste0(rail_name,": ",age_range),
#     escape = F) %>%
#   add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
#   kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
#   footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")


```

<br>

*******

<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force


## Editorial New and Trending

<br>

### Statistical Overview

To assess the difference between our control and variant group we ran a parametric test (t-test) to establish the mean differences between each group for each metric and if the difference is statistically significant.  


A p-value < 0.05 indicates the difference is statistically significant, we can reject the null hypothesis and conclude the difference seen is not due to chance.  
<br>
<br>

### Statistical Results by Age Range
For most age groups **variant 2 performed the worst for both metrics**, except for the 16-24 age group where there was a tiny uplift for starts. **Variant three showed the highest uplift across both metrics** for all age groups.


```{r stat results new trending, echo=FALSE, results = "asis"}
age_ranges<-data.frame(stats_results_edit_new_trend$age_range) %>%unique()

for(age in 1: nrow(age_ranges)) {
age_range<-age_ranges[age,1]
rail_name<-'Editorial New Trending'
comparison_var<- c('control', 'var1', 'var2', 'var3')


df<-left_join(
  get_uplift_table(stats_results_edit_new_trend, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_edit_new_trend, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
table<-df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

print(table)
}

```

<br>

### Metric Summary

```{r var totals new trending, echo=FALSE, results = "asis"}

rail_name = "Editorial New and Trending"
age_range = 'all ages'

get_summary_values(var_totals_edit_new_trend, hids_visits_summary)%>%
  kbl(booktabs = T, 
      col.names = c('Age Range', "Variant", "Users", "Visits", "Clicks", "Starts", "Completes"),
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  row_spec(c(1:4,9:12), background = "#f3f1f1")%>%
  #kable_styling(bootstrap_options = c("striped", "hover"))

kable_styling(bootstrap_options =c("hover","scale_down"))




```


*****


<br>
<br>




<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force

## Binge-Worthy

<br>

### Statistical Overview

To assess the difference between our control and variant group we ran a parametric test (t-test) to establish the mean differences between each group for each metric and if the difference is statistically significant.  


A p-value < 0.05 indicates the difference is statistically significant, we can reject the null hypothesis and conclude the difference seen is not due to chance.  
<br>
<br>

### Statistical Results by Age Range
For all age groups **variant 2 performed the worst for both metrics**. Where a statistical difference was observed,  **variant three showed the highest uplift across both metrics** in comparison to the control and variations one and two. 


```{r stat results binge-worthy, echo=FALSE, results = "asis"}
age_ranges<-data.frame(stats_results_binge_worthy$age_range) %>%unique()

for(age in 1: nrow(age_ranges)) {
age_range<-age_ranges[age,1]
rail_name<-'Binge-Worthy'
comparison_var<- c('control', 'var1', 'var2', 'var3')


df<-left_join(
  get_uplift_table(stats_results_binge_worthy, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_binge_worthy, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
table<-df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

print(table)
}

```

<br>

### Metric Summary

```{r var totals binge-worthy, echo=FALSE, results = "asis"}

rail_name = "Binge-Worthy"
age_range = 'all ages'

get_summary_values(var_totals_binge_worthy, hids_visits_summary)%>%
  kbl(booktabs = T, 
      col.names = c('Age Range', "Variant", "Users", "Visits", "Clicks", "Starts", "Completes"),
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  row_spec(c(1:4,9:12), background = "#f3f1f1")%>%
  #kable_styling(bootstrap_options = c("striped", "hover"))

kable_styling(bootstrap_options =c("hover","scale_down"))




```


*****


<br>
<br>




<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force


## Whole Homepage

<br>

### Statistical Overview

To assess the difference between our control and variant group we ran a parametric test (t-test) to establish the mean differences between each group for each metric and if the difference is statistically significant.  


A p-value < 0.05 indicates the difference is statistically significant, we can reject the null hypothesis and conclude the difference seen is not due to chance.  
<br>
<br>

### Statistical Results by Age Range
There was no significant difference in consumption of content between most of the variants across most of the age ranges when considering the homepage as a whole. A few variants did show a slight uplift against another for play starts and play completes however the uplift was not particularly large.

```{r stat results homepage, echo=FALSE, results = "asis"}
age_ranges<-data.frame(stats_results_homepage$age_range) %>%unique()

for(age in 1: nrow(age_ranges)) {
age_range<-age_ranges[age,1]
rail_name<-'Homepage'
comparison_var<- c('control', 'var1', 'var2', 'var3')


df<-left_join(
  get_uplift_table(stats_results_homepage, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_homepage, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
table<-df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

print(table)
}

```

<br>

### Metric Summary

```{r var totals homepage, echo=FALSE, results = "asis"}

rail_name = "Homepage"
age_range = 'all ages'

get_summary_values(var_totals_homepage, hids_visits_summary)%>%
  kbl(booktabs = T, 
      col.names = c('Age Range', "Variant", "Users", "Visits", "Clicks", "Starts", "Completes"),
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  row_spec(c(1:4,9:12), background = "#f3f1f1")%>%
  #kable_styling(bootstrap_options = c("striped", "hover"))

kable_styling(bootstrap_options =c("hover","scale_down"))




```


*****


<br>
<br>




<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force

## Whole Product

<br>

### Statistical Overview

To assess the difference between our control and variant group we ran a parametric test (t-test) to establish the mean differences between each group for each metric and if the difference is statistically significant.  


A p-value < 0.05 indicates the difference is statistically significant, we can reject the null hypothesis and conclude the difference seen is not due to chance.  
<br>
<br>

### Statistical Results by Age Range
There was **no significant difference in consumption of content** between any of the variants across all of the age ranges when considering the product as a whole. 


```{r stat results product, echo=FALSE, results = "asis"}
age_ranges<-data.frame(stats_results_product$age_range) %>%unique()

for(age in 1: nrow(age_ranges)) {
age_range<-age_ranges[age,1]
rail_name<-'Product'
comparison_var<- c('control', 'var1', 'var2', 'var3')


df<-left_join(
  get_uplift_table(stats_results_product, age_range, 'starts', comparison_var),
  get_uplift_table(stats_results_product, age_range, "completes",comparison_var),
  by = c("variable" = "variable", "comparison"="comparison")
)

df$uplift.x<- cell_spec(df$uplift.x, color = ifelse(df$uplift.x == 'NA', 'black',ifelse(df$uplift.x>0, 'green','red')))
df$uplift.y<- cell_spec(df$uplift.y, color = ifelse(df$uplift.y == 'NA', 'black', ifelse(df$uplift.y > 0, 'green','red')))
                                                    
table<-df%>% 
kbl(booktabs = T, col.names = c("Variant", "Comparison", "Performance", "Uplift (%)","Performance", "Uplift (%)"), 
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  add_header_above(c(" " = 2,"Starts" =2, "Completes" = 2 ))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) %>%
  footnote(general = "Uplift is calculated for the variant relative to the control. A negative value means the variant performed worse than the comparison.")

print(table)
}

```

<br>

### Metric Summary

```{r var totals product, echo=FALSE, results = "asis"}

rail_name = "Product"
age_range = 'all ages'

get_summary_values(var_totals_product, hids_visits_summary)%>%
  kbl(booktabs = T, 
      col.names = c('Age Range', "Variant", "Users", "Visits", "Clicks", "Starts", "Completes"),
      caption = paste0(rail_name,": ",age_range),
    escape = F) %>%
  row_spec(c(1:4,9:12), background = "#f3f1f1")%>%
  #kable_styling(bootstrap_options = c("striped", "hover"))

kable_styling(bootstrap_options =c("hover","scale_down"))




```


*****


<br>
<br>




<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force



## User Frequency

To considerer if users with different frequency of visits iPlayer were treated differently or responded differently to the experiment a few checks were made. 

<br>

##### Signed in Users
The same proportion of users from each frequency group were placed into each variant. This suggests that no variant was skewed towards heavy or light iPlayer users who might have responded differently to recommendations.

```{r freq groups hids, echo=FALSE, results = "asis"}
## Get a table showing the percentage split of users across the frequency bands
freq %>% 
  group_by(exp_group, frequency_group_aggregated, frequency_band) %>%
  summarise(hids = signif(sum(hids),3)) %>%
  spread(key = exp_group, value = hids) %>%
  ungroup()%>%
  mutate(control_perc = paste0(round(100*control/sum(control),0),"%"),
         var1_perc = paste0(round(100*var1/sum(var1),0),"%"),
         var2_perc = paste0(round(100*var2/sum(var2),0),"%"),
         var3_perc = paste0(round(100*var3/sum(var3),0),"%")
         )%>%
  select(-control, -var1, -var2, -var3)%>%
  rename(control = control_perc,
         var1 = var1_perc,
         var2 = var2_perc,
         var3 = var3_perc
         )%>%
arrange(frequency_band)%>% 
kbl(booktabs = T, col.names = c("Aggregated Group", "Band", "Control", "Var1","Var2", "Var3"), 
      caption = "Percentage of users in each frequency group.",
    escape = F) %>%
  add_header_above(c("Frequency" = 2,"Percentage of Signed in Users" =4))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) 
```

<br>

##### Play Completes from the Homepage
The percentage of play completes coming from clicks on the homepage across each frequency group was the same for all variants. This supports the above results in suggesting that no variant was affected differently by users of different frequencies. This was true for clicks on the homepage, play starts and play completes. 

```{r freq groups completes, echo=FALSE, results = "asis"}
## Get a table showing the percentage split of users across the frequency bands
freq %>% 
  group_by(exp_group, frequency_group_aggregated, frequency_band) %>%
  summarise(completes = signif(sum(completes),3)) %>%
  spread(key = exp_group, value = completes) %>%
  ungroup()%>%
  mutate(control_perc = paste0(round(100*control/sum(control),0),"%"),
         var1_perc = paste0(round(100*var1/sum(var1),0),"%"),
         var2_perc = paste0(round(100*var2/sum(var2),0),"%"),
         var3_perc = paste0(round(100*var3/sum(var3),0),"%")
         )%>%
  select(-control, -var1, -var2, -var3)%>%
  rename(control = control_perc,
         var1 = var1_perc,
         var2 = var2_perc,
         var3 = var3_perc
         )%>%
arrange(frequency_band)%>% 
kbl(booktabs = T, col.names = c("Aggregated Group", "Band", "Control", "Var1","Var2", "Var3"), 
      caption = "Percentage of completes coming from users in each frequency group.",
    escape = F) %>%
  add_header_above(c("Frequency" = 2,"Percentage of Play Completes" =4))%>%
  kable_styling(bootstrap_options =c("striped", "scale_down","hover")) 



```

*****


<br>
<br>




<br>
<br>
<br>
<b>Contact</b> <br>
email: `dataforce@bbc.co.uk`<br>
slack: #help-data-force
